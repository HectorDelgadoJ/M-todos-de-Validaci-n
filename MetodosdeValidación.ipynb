{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXMY7e86mpNjTWbAblEj8c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HectorDelgadoJ/M-todos-de-Validaci-n/blob/main/MetodosdeValidaci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métodos de validación\n",
        "En esta práctica exploraremos tres métodos de validación comunes en aprendizaje automático: Hold-Out, K-Fold Cross-Validation y Leave-One-Out, utilizando el Wine Dataset del repositorio UCI. Estos métodos nos permiten evaluar el rendimiento de un modelo clasificatorio al dividir el conjunto de datos en subconjuntos de entrenamiento y prueba, asegurando que los resultados sean confiables y aplicables a nuevos datos.\n",
        "El objetivo es implementar cada uno de estos métodos con el clasificador K-Nearest Neighbors (KNN), generando conjuntos de datos disjuntos para su entrenamiento y evaluación. Posteriormente, compararemos la precisión obtenida con cada técnica para determinar cuál se adapta mejor al dataset y proporciona una mejor generalización."
      ],
      "metadata": {
        "id": "3CB7AWqvfMCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ##   1 Cargamos el Wine Dataset"
      ],
      "metadata": {
        "id": "IAniF8KbnJb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar el dataset\n",
        "wine = load_wine(as_frame=True)\n",
        "df_wine = wine.frame\n",
        "\n",
        "# Separar características (X) y etiquetas (y)\n",
        "X = df_wine.iloc[:, :-1]  # Todas las columnas excepto la última (características)\n",
        "y = df_wine.iloc[:, -1]   # Última columna (etiquetas)\n"
      ],
      "metadata": {
        "id": "7v2xw0DvnD9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ##  2 Hold-Out Validation\n",
        "\n",
        "Puedes fijar el valor de r como el porcentaje de datos para el conjunto de prueba."
      ],
      "metadata": {
        "id": "vmEqKsPFnZGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Método Hold-Out Validation\n",
        "def hold_out_validation(X, y, test_size):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Ejemplo con 20% de datos para el conjunto de prueba\n",
        "X_train, X_test, y_train, y_test = hold_out_validation(X, y, 0.2)\n"
      ],
      "metadata": {
        "id": "jWQxOdUzno-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ##  3 K-Fold Cross-Validation\n",
        "\n",
        "Aquí, K es el número de particiones y lo defines tú."
      ],
      "metadata": {
        "id": "3Fm1KVyInx4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Método K-Fold Cross-Validation\n",
        "def k_fold_validation(X, y, k):\n",
        "    kf = KFold(n_splits=k)\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        # Puedes entrenar y evaluar un modelo en cada partición\n",
        "        print(f\"Train indices: {train_index}, Test indices: {test_index}\")\n",
        "\n",
        "# Ejemplo con K = 5\n",
        "k_fold_validation(X, y, 5)\n"
      ],
      "metadata": {
        "id": "azOsbAGFn2yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ## 4 Leave-One-Out Validation\n",
        "\n",
        "Leave-One-Out valida dejando una sola muestra para el conjunto de prueba en cada iteración."
      ],
      "metadata": {
        "id": "gkbhVYLSn6Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "# Método Leave-One-Out Validation\n",
        "def leave_one_out_validation(X, y):\n",
        "    loo = LeaveOneOut()\n",
        "    for train_index, test_index in loo.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        # Puedes entrenar y evaluar un modelo en cada partición\n",
        "        print(f\"Train indices: {train_index}, Test index: {test_index}\")\n",
        "\n",
        "# Ejecutar Leave-One-Out\n",
        "leave_one_out_validation(X, y)\n"
      ],
      "metadata": {
        "id": "lqfgXbEToPc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ## 5 Entrenamiento y evaluación\n",
        "\n"
      ],
      "metadata": {
        "id": "JsXNJO4vod7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Entrenar y evaluar un modelo en Hold-Out\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Hold-Out Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "gLtDtkybokvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultado Final"
      ],
      "metadata": {
        "id": "dL6e8lcKopvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar el Wine Dataset\n",
        "wine = load_wine(as_frame=True)\n",
        "df_wine = wine.frame\n",
        "\n",
        "# Separar características (X) y etiquetas (y)\n",
        "X = df_wine.iloc[:, :-1]\n",
        "y = df_wine.iloc[:, -1]\n",
        "\n",
        "# Modelo de clasificación\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Función para Hold-Out Validation\n",
        "def hold_out_validation(X, y, test_size):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Hold-Out Accuracy (test_size={test_size}): {accuracy}\")\n",
        "\n",
        "# Función para K-Fold Cross-Validation\n",
        "def k_fold_validation(X, y, k):\n",
        "    kf = KFold(n_splits=k)\n",
        "    accuracies = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracies.append(accuracy)\n",
        "    print(f\"K-Fold Accuracy (K={k}): {sum(accuracies)/len(accuracies)}\")\n",
        "\n",
        "# Función para Leave-One-Out Validation\n",
        "def leave_one_out_validation(X, y):\n",
        "    loo = LeaveOneOut()\n",
        "    accuracies = []\n",
        "    for train_index, test_index in loo.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_pred = knn.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracies.append(accuracy)\n",
        "    print(f\"Leave-One-Out Accuracy: {sum(accuracies)/len(accuracies)}\")\n",
        "\n",
        "# Ejemplo de uso\n",
        "print(\"Wine Dataset Validation Results:\")\n",
        "\n",
        "# Hold-Out Validation (con el 20% de datos para prueba)\n",
        "hold_out_validation(X, y, 0.2)\n",
        "\n",
        "# K-Fold Cross-Validation (con K=5)\n",
        "k_fold_validation(X, y, 5)\n",
        "\n",
        "# Leave-One-Out Validation\n",
        "leave_one_out_validation(X, y)\n"
      ],
      "metadata": {
        "id": "sEdWSV7louFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo de Salida"
      ],
      "metadata": {
        "id": "XWyRNJ9rov_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Wine Dataset Validation Results:\n",
        "Hold-Out Accuracy (test_size=0.2): 0.9722222222222222\n",
        "K-Fold Accuracy (K=5): 0.9662921348314607\n",
        "Leave-One-Out Accuracy: 0.9887640449438202\n"
      ],
      "metadata": {
        "id": "0pgZXI6lo0hP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}